{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346b2cc-727f-4872-8398-d93c5980e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    average_attention_matrix_file = \"/piech/u/joetey/multimodal-reasoning/results/files/results_geometry_3k_baseline_cot_20240601_194854/attention_weights/0.pt\"\n",
    "    average_attention_matrix = torch.load(average_attention_matrix_file, map_location=torch.device('cpu'))\n",
    "    attention_file = \"/piech/u/joetey/multimodal-reasoning/results/files/results_geometry_3k_baseline_cot_20240601_194854/attention/0.json\"\n",
    "    with open(attention_file, \"r\") as file:\n",
    "        attention_description = json.load(file)\n",
    "\n",
    "    image_file = '/piech/u/joetey/multimodal-reasoning/dataset/eval/geometry_3k/images/' + attention_description[\"image_file\"].split(\"/\")[-1]\n",
    "    output_tokens = [token.replace('Ġ', '').replace('Ċ', '') for token in attention_description[\"output_tokens\"]]\n",
    "    input_tokens = [token.replace('Ġ', '').replace('Ċ', '') for token in attention_description[\"input_tokens\"]]\n",
    "    \n",
    "    image_token_indices = [i for i, token in enumerate(input_tokens) if token.startswith(\"image_\")]\n",
    "    x_image_token_start = image_token_indices[0]\n",
    "    x_image_token_end = image_token_indices[-1] + 1\n",
    "    main_input_text = input_tokens[x_image_token_end + 1:len(input_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e60b2-572d-431d-ab6e-62c3045fa2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd8e45-2a53-401a-b447-6be39a560ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de612ae-9e4d-4ca0-9f17-235ee4b2c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def calculate_attention_values(attention_matrix, input_tokens, output_tokens, image_token_start_idx, image_token_end_idx):\n",
    "    # Calculate the average image tokens for each output token before normalizing\n",
    "    average_attention_scores = []\n",
    "\n",
    "    # calculate rationale's attention scores\n",
    "    for i, output_token in enumerate(output_tokens):\n",
    "        output_relevancy = attention_matrix[len(input_tokens) - 1 + i, :]\n",
    "        image_tokens = output_relevancy[image_token_start_idx:image_token_end_idx]\n",
    "        text_tokens = output_relevancy[image_token_end_idx + 1:len(input_tokens)-3]\n",
    "    \n",
    "        average_text_tokens = np.mean(text_tokens)\n",
    "        average_image_tokens = np.mean(image_tokens)\n",
    "        \n",
    "        average_attention_scores.append({\n",
    "            \"id\": i,\n",
    "            \"output_token\": output_token,\n",
    "            \"average_text\": average_text_tokens,\n",
    "            \"average_image_tokens\": average_image_tokens\n",
    "        })\n",
    "\n",
    "    return average_attention_scores \n",
    "\n",
    "def calculate_image_text_ratio(attention_scores, normalize=True):\n",
    "    ratio_list = []\n",
    "    for output_token in attention_scores:\n",
    "        ratio_list.append(output_token[\"average_image_tokens\"] / output_token[\"average_text\"])\n",
    "\n",
    "    ratio_list = np.array(ratio_list)\n",
    "    \n",
    "    return np.max(ratio_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
